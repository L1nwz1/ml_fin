{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80418d16",
   "metadata": {},
   "source": [
    "# 7 特征工程\n",
    "\n",
    "改编自 sklearn样例 https://scikit-learn.org/stable/auto_examples/impute/plot_iterative_imputer_variants_comparison.html#sphx-glr-auto-examples-impute-plot-iterative-imputer-variants-comparison-py\n",
    "\n",
    "本例使用加州房价数据，人为添加了数据缺失，对比了不同填补方案的差异\n",
    "\n",
    "请注意代码风格使用了pipeline，不同于我们之前的toy风格\n",
    "\n",
    "如果感觉阅读有困难，可先学习pipeline相关知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c17af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# To use this experimental feature, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import BayesianRidge, Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc909d11",
   "metadata": {},
   "source": [
    "## 7.1 缺失值填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa18694",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('california_housing.csv')\n",
    "feature_names = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
    "X_full = dataset[feature_names].values\n",
    "y_full = dataset['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f71522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#只使用十分之一数据作说明，不运行这两行代码即使用全样本\n",
    "X_full = X_full[::10]\n",
    "y_full = y_full[::10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X_full.shape\n",
    "# Estimate the score on the entire dataset, with no missing values\n",
    "#相较于原例，我们使用岭回归而非贝叶斯版本的岭回归\n",
    "br_estimator = Ridge()\n",
    "score_full_data = pd.DataFrame(\n",
    "    cross_val_score(\n",
    "        br_estimator, X_full, y_full, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    ),\n",
    "    columns=[\"Full Data\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a single missing value to each row\n",
    "#这里给每一行、每一列都添加了缺失值，这种程度的缺失其实比较罕见的\n",
    "rng = np.random.RandomState(0)\n",
    "X_missing = X_full.copy()\n",
    "y_missing = y_full\n",
    "missing_samples = np.arange(n_samples)\n",
    "missing_features = rng.choice(n_features, n_samples, replace=True)\n",
    "X_missing[missing_samples, missing_features] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.isnan(X_missing[:,col_i]).sum() for col_i in range(n_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8efe39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de86692",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2073495c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e55daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the score after imputation (mean and median strategies)\n",
    "# 计算简单填补的表现\n",
    "score_simple_imputer = pd.DataFrame()\n",
    "for strategy in (\"mean\", \"median\"):\n",
    "    estimator = make_pipeline(\n",
    "        #在流水线放入以均值、中位数为填补的 SimpleImputer\n",
    "        SimpleImputer(missing_values=np.nan, strategy=strategy), br_estimator\n",
    "    )\n",
    "    #计算交叉验证分数\n",
    "    score_simple_imputer[strategy] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算knn填补的表现\n",
    "score_simple_knn = pd.DataFrame()\n",
    "for strategy in (\"uniform\", \"distance\"):\n",
    "    estimator = make_pipeline(\n",
    "        #在流水线放入 KNNImputer\n",
    "        KNNImputer(missing_values=np.nan, n_neighbors=2, weights=strategy), br_estimator\n",
    "    )\n",
    "    #计算交叉验证分数\n",
    "    score_simple_knn[strategy] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Estimate the score after iterative imputation of the missing values\n",
    "# with different estimators\n",
    "#使用以下四种复杂的填补方法\n",
    "estimators = [\n",
    "    BayesianRidge(),\n",
    "    #贝叶斯岭回归\n",
    "    RandomForestRegressor(\n",
    "        # We tuned the hyperparameters of the RandomForestRegressor to get a good\n",
    "        # enough predictive performance for a restricted execution time.\n",
    "        n_estimators=4,\n",
    "        max_depth=10,\n",
    "        bootstrap=True,\n",
    "        max_samples=0.5,\n",
    "        n_jobs=2,\n",
    "        random_state=0,\n",
    "    ),\n",
    "    #随机森林回归\n",
    "    make_pipeline(\n",
    "        Nystroem(kernel=\"polynomial\", degree=2, random_state=0), Ridge(alpha=1e3)\n",
    "    ),\n",
    "    #使用核方法的岭回归\n",
    "    KNeighborsRegressor(n_neighbors=15),\n",
    "    #k临近回归\n",
    "    \n",
    "    #显然，这些用于填补缺失值的回归方法都很复杂，\n",
    "]\n",
    "#新建dataframe以保存分数\n",
    "score_iterative_imputer = pd.DataFrame()\n",
    "# iterative imputer is sensible to the tolerance and\n",
    "# dependent on the estimator used internally.\n",
    "# we tuned the tolerance to keep this example run with limited computational\n",
    "# resources while not changing the results too much compared to keeping the\n",
    "# stricter default value for the tolerance parameter.\n",
    "\n",
    "tolerances = (1e-3, 1e-1, 1e-1, 1e-2)\n",
    "for impute_estimator, tol in zip(estimators, tolerances):\n",
    "    estimator = make_pipeline(\n",
    "        IterativeImputer(\n",
    "            #尝试不同种的estimator，max_iter 最大迭代次数，tol 拟合终点的误差值，迭代中误差小于该值或迭代次数大于max_iter即停止\n",
    "            random_state=0, estimator=impute_estimator, max_iter=25, tol=tol\n",
    "        ),\n",
    "        #最终的回归还是ridge\n",
    "        br_estimator,\n",
    "    )\n",
    "    score_iterative_imputer[impute_estimator.__class__.__name__] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "\n",
    "scores = pd.concat(\n",
    "    [score_full_data, score_simple_imputer,score_simple_knn, score_iterative_imputer],\n",
    "    keys=[\"Original\", \"SimpleImputer\",'KNNImputer', \"IterativeImputer\"],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5594482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot california housing results\n",
    "fig, ax = plt.subplots(figsize=(13, 6))\n",
    "means = -scores.mean()\n",
    "errors = scores.std()\n",
    "means.plot.barh(xerr=errors, ax=ax)\n",
    "ax.set_title(\"California Housing Regression with Different Imputation Methods\")\n",
    "ax.set_xlabel(\"MSE (smaller is better)\")\n",
    "ax.set_yticks(np.arange(means.shape[0]))\n",
    "ax.set_yticklabels([\" w/ \".join(label) for label in means.index.tolist()])\n",
    "plt.tight_layout(pad=1)\n",
    "plt.savefig('缺失_2k_逐行.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2k_perrow = scores.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb16299",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "dataset = pd.read_csv('california_housing.csv')\n",
    "feature_names = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
    "X_full = dataset[feature_names].values\n",
    "y_full = dataset['y'].values\n",
    "\n",
    "n_samples, n_features = X_full.shape\n",
    "# Estimate the score on the entire dataset, with no missing values\n",
    "#相较于原例，我们使用岭回归而非贝叶斯版本的岭回归\n",
    "br_estimator = Ridge()\n",
    "score_full_data = pd.DataFrame(\n",
    "    cross_val_score(\n",
    "        br_estimator, X_full, y_full, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    ),\n",
    "    columns=[\"Full Data\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Add a single missing value to each row\n",
    "#这里给每一行、每一列都添加了缺失值，这种程度的缺失其实比较罕见的\n",
    "X_missing = X_full.copy()\n",
    "y_missing = y_full\n",
    "missing_samples = np.arange(n_samples)\n",
    "missing_features = rng.choice(n_features, n_samples, replace=True)\n",
    "X_missing[missing_samples, missing_features] = np.nan\n",
    "\n",
    "\n",
    "# Estimate the score after imputation (mean and median strategies)\n",
    "# 计算简单填补的表现\n",
    "score_simple_imputer = pd.DataFrame()\n",
    "for strategy in (\"mean\", \"median\"):\n",
    "    estimator = make_pipeline(\n",
    "        #在流水线放入以均值、中位数为填补的 SimpleImputer\n",
    "        SimpleImputer(missing_values=np.nan, strategy=strategy), br_estimator\n",
    "    )\n",
    "    #计算交叉验证分数\n",
    "    score_simple_imputer[strategy] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "    \n",
    "# 计算knn填补的表现\n",
    "score_simple_knn = pd.DataFrame()\n",
    "for strategy in (\"uniform\", \"distance\"):\n",
    "    estimator = make_pipeline(\n",
    "        #在流水线放入 KNNImputer\n",
    "        KNNImputer(missing_values=np.nan, n_neighbors=2, weights=strategy), br_estimator\n",
    "    )\n",
    "    #计算交叉验证分数\n",
    "    score_simple_knn[strategy] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "    \n",
    "\n",
    "# Estimate the score after iterative imputation of the missing values\n",
    "# with different estimators\n",
    "#使用以下四种复杂的填补方法\n",
    "estimators = [\n",
    "    BayesianRidge(),\n",
    "    #贝叶斯岭回归\n",
    "    RandomForestRegressor(\n",
    "        # We tuned the hyperparameters of the RandomForestRegressor to get a good\n",
    "        # enough predictive performance for a restricted execution time.\n",
    "        n_estimators=4,\n",
    "        max_depth=10,\n",
    "        bootstrap=True,\n",
    "        max_samples=0.5,\n",
    "        n_jobs=2,\n",
    "        random_state=0,\n",
    "    ),\n",
    "    #随机森林回归\n",
    "    make_pipeline(\n",
    "        Nystroem(kernel=\"polynomial\", degree=2, random_state=0), Ridge(alpha=1e3)\n",
    "    ),\n",
    "    #使用核方法的岭回归\n",
    "    KNeighborsRegressor(n_neighbors=15),\n",
    "    #k临近回归\n",
    "    \n",
    "    #显然，这些用于填补缺失值的回归方法都很复杂，\n",
    "]\n",
    "#新建dataframe以保存分数\n",
    "score_iterative_imputer = pd.DataFrame()\n",
    "# iterative imputer is sensible to the tolerance and\n",
    "# dependent on the estimator used internally.\n",
    "# we tuned the tolerance to keep this example run with limited computational\n",
    "# resources while not changing the results too much compared to keeping the\n",
    "# stricter default value for the tolerance parameter.\n",
    "\n",
    "tolerances = (1e-3, 1e-1, 1e-1, 1e-2)\n",
    "for impute_estimator, tol in zip(estimators, tolerances):\n",
    "    estimator = make_pipeline(\n",
    "        IterativeImputer(\n",
    "            #尝试不同种的estimator，max_iter 最大迭代次数，tol 拟合终点的误差值，迭代中误差小于该值或迭代次数大于max_iter即停止\n",
    "            random_state=0, estimator=impute_estimator, max_iter=25, tol=tol\n",
    "        ),\n",
    "        #最终的回归还是ridge\n",
    "        br_estimator,\n",
    "    )\n",
    "    score_iterative_imputer[impute_estimator.__class__.__name__] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "\n",
    "scores = pd.concat(\n",
    "    [score_full_data, score_simple_imputer,score_simple_knn, score_iterative_imputer],\n",
    "    keys=[\"Original\", \"SimpleImputer\",'KNNImputer', \"IterativeImputer\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# plot california housing results\n",
    "fig, ax = plt.subplots(figsize=(13, 6))\n",
    "means = -scores.mean()\n",
    "errors = scores.std()\n",
    "means.plot.barh(xerr=errors, ax=ax)\n",
    "ax.set_title(\"California Housing Regression with Different Imputation Methods\")\n",
    "ax.set_xlabel(\"MSE (smaller is better)\")\n",
    "ax.set_yticks(np.arange(means.shape[0]))\n",
    "ax.set_yticklabels([\" w/ \".join(label) for label in means.index.tolist()])\n",
    "plt.tight_layout(pad=1)\n",
    "plt.savefig('缺失_20k_逐行.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20k_perrow = scores.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae543925",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "dataset = pd.read_csv('california_housing.csv')\n",
    "feature_names = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
    "X_full = dataset[feature_names].values\n",
    "y_full = dataset['y'].values\n",
    "\n",
    "X_full = X_full[::10]\n",
    "y_full = y_full[::10]\n",
    "\n",
    "\n",
    "n_samples, n_features = X_full.shape\n",
    "# Estimate the score on the entire dataset, with no missing values\n",
    "#相较于原例，我们使用岭回归而非贝叶斯版本的岭回归\n",
    "br_estimator = Ridge()\n",
    "score_full_data = pd.DataFrame(\n",
    "    cross_val_score(\n",
    "        br_estimator, X_full, y_full, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    ),\n",
    "    columns=[\"Full Data\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Add a single missing value to each row\n",
    "#这里给每一行、每一列都添加了缺失值，这种程度的缺失其实比较罕见的\n",
    "X_missing = X_full.copy()\n",
    "y_missing = y_full\n",
    "missing_samples = np.arange(n_samples)\n",
    "missing_features = rng.choice(4, n_samples, replace=True)\n",
    "X_missing[missing_samples, missing_features] = np.nan\n",
    "\n",
    "\n",
    "# Estimate the score after imputation (mean and median strategies)\n",
    "# 计算简单填补的表现\n",
    "score_simple_imputer = pd.DataFrame()\n",
    "for strategy in (\"mean\", \"median\"):\n",
    "    estimator = make_pipeline(\n",
    "        #在流水线放入以均值、中位数为填补的 SimpleImputer\n",
    "        SimpleImputer(missing_values=np.nan, strategy=strategy), br_estimator\n",
    "    )\n",
    "    #计算交叉验证分数\n",
    "    score_simple_imputer[strategy] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "# 计算knn填补的表现\n",
    "score_simple_knn = pd.DataFrame()\n",
    "for strategy in (\"uniform\", \"distance\"):\n",
    "    estimator = make_pipeline(\n",
    "        #在流水线放入 KNNImputer\n",
    "        KNNImputer(missing_values=np.nan, n_neighbors=2, weights=strategy), br_estimator\n",
    "    )\n",
    "    #计算交叉验证分数\n",
    "    score_simple_knn[strategy] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "       \n",
    "\n",
    "\n",
    "# Estimate the score after iterative imputation of the missing values\n",
    "# with different estimators\n",
    "#使用以下四种复杂的填补方法\n",
    "estimators = [\n",
    "    BayesianRidge(),\n",
    "    #贝叶斯岭回归\n",
    "    RandomForestRegressor(\n",
    "        # We tuned the hyperparameters of the RandomForestRegressor to get a good\n",
    "        # enough predictive performance for a restricted execution time.\n",
    "        n_estimators=4,\n",
    "        max_depth=10,\n",
    "        bootstrap=True,\n",
    "        max_samples=0.5,\n",
    "        n_jobs=2,\n",
    "        random_state=0,\n",
    "    ),\n",
    "    #随机森林回归\n",
    "    make_pipeline(\n",
    "        Nystroem(kernel=\"polynomial\", degree=2, random_state=0), Ridge(alpha=1e3)\n",
    "    ),\n",
    "    #使用核方法的岭回归\n",
    "    KNeighborsRegressor(n_neighbors=15),\n",
    "    #k临近回归\n",
    "    \n",
    "    #显然，这些用于填补缺失值的回归方法都很复杂，\n",
    "]\n",
    "#新建dataframe以保存分数\n",
    "score_iterative_imputer = pd.DataFrame()\n",
    "# iterative imputer is sensible to the tolerance and\n",
    "# dependent on the estimator used internally.\n",
    "# we tuned the tolerance to keep this example run with limited computational\n",
    "# resources while not changing the results too much compared to keeping the\n",
    "# stricter default value for the tolerance parameter.\n",
    "\n",
    "tolerances = (1e-3, 1e-1, 1e-1, 1e-2)\n",
    "for impute_estimator, tol in zip(estimators, tolerances):\n",
    "    estimator = make_pipeline(\n",
    "        IterativeImputer(\n",
    "            #尝试不同种的estimator，max_iter 最大迭代次数，tol 拟合终点的误差值，迭代中误差小于该值或迭代次数大于max_iter即停止\n",
    "            random_state=0, estimator=impute_estimator, max_iter=25, tol=tol\n",
    "        ),\n",
    "        #最终的回归还是ridge\n",
    "        br_estimator,\n",
    "    )\n",
    "    score_iterative_imputer[impute_estimator.__class__.__name__] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "\n",
    "scores = pd.concat(\n",
    "    [score_full_data, score_simple_imputer,score_simple_knn, score_iterative_imputer],\n",
    "    keys=[\"Original\", \"SimpleImputer\",'KNNImputer', \"IterativeImputer\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# plot california housing results\n",
    "fig, ax = plt.subplots(figsize=(13, 6))\n",
    "means = -scores.mean()\n",
    "errors = scores.std()\n",
    "means.plot.barh(xerr=errors, ax=ax)\n",
    "ax.set_title(\"California Housing Regression with Different Imputation Methods\")\n",
    "ax.set_xlabel(\"MSE (smaller is better)\")\n",
    "ax.set_yticks(np.arange(means.shape[0]))\n",
    "ax.set_yticklabels([\" w/ \".join(label) for label in means.index.tolist()])\n",
    "plt.tight_layout(pad=1)\n",
    "plt.savefig('缺失_2k_逐行_half_col.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d992ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2k_perrow_halfcol = scores.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e008526",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "dataset = pd.read_csv('california_housing.csv')\n",
    "feature_names = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
    "X_full = dataset[feature_names].values\n",
    "y_full = dataset['y'].values\n",
    "\n",
    "X_full = X_full[::10]\n",
    "y_full = y_full[::10]\n",
    "\n",
    "\n",
    "n_samples, n_features = X_full.shape\n",
    "# Estimate the score on the entire dataset, with no missing values\n",
    "#相较于原例，我们使用岭回归而非贝叶斯版本的岭回归\n",
    "br_estimator = Ridge()\n",
    "score_full_data = pd.DataFrame(\n",
    "    cross_val_score(\n",
    "        br_estimator, X_full, y_full, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    ),\n",
    "    columns=[\"Full Data\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Add a single missing value to each row\n",
    "#这里给每一行、每一列都添加了缺失值，这种程度的缺失其实比较罕见的\n",
    "X_missing = X_full.copy()\n",
    "y_missing = y_full\n",
    "missing_samples = np.arange(int(n_samples/2))\n",
    "missing_features = rng.choice(n_features, int(n_samples/2), replace=True)\n",
    "X_missing[missing_samples*2, missing_features] = np.nan\n",
    "\n",
    "\n",
    "# Estimate the score after imputation (mean and median strategies)\n",
    "# 计算简单填补的表现\n",
    "score_simple_imputer = pd.DataFrame()\n",
    "for strategy in (\"mean\", \"median\"):\n",
    "    estimator = make_pipeline(\n",
    "        #在流水线放入以均值、中位数为填补的 SimpleImputer\n",
    "        SimpleImputer(missing_values=np.nan, strategy=strategy), br_estimator\n",
    "    )\n",
    "    #计算交叉验证分数\n",
    "    score_simple_imputer[strategy] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "    \n",
    "# 计算knn填补的表现\n",
    "score_simple_knn = pd.DataFrame()\n",
    "for strategy in (\"uniform\", \"distance\"):\n",
    "    estimator = make_pipeline(\n",
    "        #在流水线放入 KNNImputer\n",
    "        KNNImputer(missing_values=np.nan, n_neighbors=2, weights=strategy), br_estimator\n",
    "    )\n",
    "    #计算交叉验证分数\n",
    "    score_simple_knn[strategy] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "\n",
    "\n",
    "# Estimate the score after iterative imputation of the missing values\n",
    "# with different estimators\n",
    "#使用以下四种复杂的填补方法\n",
    "estimators = [\n",
    "    BayesianRidge(),\n",
    "    #贝叶斯岭回归\n",
    "    RandomForestRegressor(\n",
    "        # We tuned the hyperparameters of the RandomForestRegressor to get a good\n",
    "        # enough predictive performance for a restricted execution time.\n",
    "        n_estimators=4,\n",
    "        max_depth=10,\n",
    "        bootstrap=True,\n",
    "        max_samples=0.5,\n",
    "        n_jobs=2,\n",
    "        random_state=0,\n",
    "    ),\n",
    "    #随机森林回归\n",
    "    make_pipeline(\n",
    "        Nystroem(kernel=\"polynomial\", degree=2, random_state=0), Ridge(alpha=1e3)\n",
    "    ),\n",
    "    #使用核方法的岭回归\n",
    "    KNeighborsRegressor(n_neighbors=15),\n",
    "    #k临近回归\n",
    "    \n",
    "    #显然，这些用于填补缺失值的回归方法都很复杂，\n",
    "]\n",
    "#新建dataframe以保存分数\n",
    "score_iterative_imputer = pd.DataFrame()\n",
    "# iterative imputer is sensible to the tolerance and\n",
    "# dependent on the estimator used internally.\n",
    "# we tuned the tolerance to keep this example run with limited computational\n",
    "# resources while not changing the results too much compared to keeping the\n",
    "# stricter default value for the tolerance parameter.\n",
    "\n",
    "tolerances = (1e-3, 1e-1, 1e-1, 1e-2)\n",
    "for impute_estimator, tol in zip(estimators, tolerances):\n",
    "    estimator = make_pipeline(\n",
    "        IterativeImputer(\n",
    "            #尝试不同种的estimator，max_iter 最大迭代次数，tol 拟合终点的误差值，迭代中误差小于该值或迭代次数大于max_iter即停止\n",
    "            random_state=0, estimator=impute_estimator, max_iter=25, tol=tol\n",
    "        ),\n",
    "        #最终的回归还是ridge\n",
    "        br_estimator,\n",
    "    )\n",
    "    score_iterative_imputer[impute_estimator.__class__.__name__] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "\n",
    "scores = pd.concat(\n",
    "    [score_full_data, score_simple_imputer,score_simple_knn, score_iterative_imputer],\n",
    "    keys=[\"Original\", \"SimpleImputer\",'KNNImputer', \"IterativeImputer\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# plot california housing results\n",
    "fig, ax = plt.subplots(figsize=(13, 6))\n",
    "means = -scores.mean()\n",
    "errors = scores.std()\n",
    "means.plot.barh(xerr=errors, ax=ax)\n",
    "ax.set_title(\"California Housing Regression with Different Imputation Methods\")\n",
    "ax.set_xlabel(\"MSE (smaller is better)\")\n",
    "ax.set_yticks(np.arange(means.shape[0]))\n",
    "ax.set_yticklabels([\" w/ \".join(label) for label in means.index.tolist()])\n",
    "plt.tight_layout(pad=1)\n",
    "plt.savefig('缺失_2k_半行.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2k_halfrow = scores.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0200fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_score = pd.concat(\n",
    "    [df_2k_perrow, df_20k_perrow, df_2k_perrow_halfcol,df_2k_halfrow],\n",
    "    keys=[\"base\", \"20k\", \"hal col\",'half row'],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed28db",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_score.to_csv('compare_different_missing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa760f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot california housing results\n",
    "fig, ax = plt.subplots(figsize=(13, 6))\n",
    "scores = full_score\n",
    "means = -scores.mean()\n",
    "errors = scores.std()\n",
    "means.plot.barh(xerr=errors, ax=ax)\n",
    "ax.set_title(\"California Housing Regression with Different Imputation Methods\")\n",
    "ax.set_xlabel(\"MSE (smaller is better)\")\n",
    "ax.set_yticks(np.arange(means.shape[0]))\n",
    "ax.set_yticklabels([\"--\".join(label) for label in means.index.tolist()])\n",
    "plt.tight_layout(pad=1)\n",
    "plt.savefig('缺失大全.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845f6cbe",
   "metadata": {},
   "source": [
    "## 7.2 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0772210",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [['男','学士','程序员'],\n",
    "    ['女','硕士','公务员'],\n",
    "    ['男','博士','外卖员'],\n",
    "    ['女',np.nan,'交易员']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa45d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "enc_ord = preprocessing.OrdinalEncoder()\n",
    "enc_ord.fit(X)\n",
    "enc_ord.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_ord.transform([['女','硕士','教师']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_ord = preprocessing.OrdinalEncoder(encoded_missing_value=-1)\n",
    "enc_ord.fit(X)\n",
    "enc_ord.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88dc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_oh = preprocessing.OneHotEncoder()\n",
    "enc_oh.fit(X)\n",
    "enc_oh.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0350426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc_oh.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086672cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_oh.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0491a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_oh.transform([['女','硕士','教师']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d649ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_oh = preprocessing.OneHotEncoder(handle_unknown='infrequent_if_exist')\n",
    "enc_oh.fit(X)\n",
    "enc_oh.transform(X)\n",
    "enc_oh.transform([['女','硕士','教师']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af6fb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4f291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a93bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69865a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
