{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480b43cc",
   "metadata": {},
   "source": [
    "# 3.支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e4947",
   "metadata": {},
   "source": [
    "## 3.1 维度诅咒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fab8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample = 500\n",
    "max_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db49739",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 指定默认字体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决保存图像是负号'-'显示为方块的问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidien_distence(x, y):\n",
    "    #计算两个向量x和y的欧氏距离\n",
    "    vec1, vec2 = np.mat(x), np.mat(y)\n",
    "    return np.sqrt(np.sum(np.square(vec1 - vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(dim):\n",
    "    #生成dim维的N_sample个数据，数据格式：500*dim\n",
    "    data = [[] for _ in range(N_sample)]\n",
    "    for i in range(N_sample):\n",
    "        for j in range(dim):\n",
    "            num = random.random()\n",
    "            data[i].append(num)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff009cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这部分代码需要一些时间来运行\n",
    "euc_diff_list = [] # 存储欧氏距离下最大最小距离之间的距离\n",
    "time_0 = time.time()\n",
    "for dim in range(1, max_dim+1): # 由于1维情况，无法计算余弦相似度，故从2-50维\n",
    "    if dim % 10 == 1:\n",
    "        print(dim,int(time.time()-time_0))\n",
    "    data = generate_data(dim)\n",
    "    euc_distence_list = []\n",
    "    for i in range(N_sample-1):\n",
    "        for j in range(i+1, N_sample):\n",
    "            euc_distence_list.append(euclidien_distence(data[i], data[j]))\n",
    "            \n",
    "    euc_diff_list.append(math.log((max(euc_distence_list) - min(euc_distence_list))/min(euc_distence_list), 10))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136fec1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "x = list(range(1, max_dim+1))\n",
    "\n",
    "plt.plot(x, euc_diff_list, label = '欧氏距离 最大/最小')\n",
    "plt.title('Curse of Dimensionality')\n",
    "plt.xlabel('维度')\n",
    "plt.ylabel('lg(欧氏距离)')\n",
    "plt.legend(loc = 'upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84fe17",
   "metadata": {},
   "source": [
    "## 3.2 超参数：gamma与C\n",
    "\n",
    "修改自CSDN，链接 https://blog.csdn.net/OldDriver1995/article/details/105211038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2627e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
    "def plot_dataset(X, y, axes):\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bd\")\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"rd\")\n",
    "    plt.axis(axes)\n",
    "    plt.grid(True, which='both')\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=20, rotation=0)\n",
    "\n",
    "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(clf, axes):\n",
    "    x1= np.linspace(axes[0], axes[1], 100)\n",
    "    x2= np.linspace(axes[0], axes[1], 100)\n",
    "    xx, yy = np.meshgrid(x1, x2)\n",
    "    x_new = np.c_[xx.ravel(), yy.ravel()]\n",
    "    y_pred = clf.predict(x_new).reshape(xx.shape)\n",
    "    y_decision=clf.decision_function(x_new).reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, y_pred, alpha = 0.4, cmap='coolwarm')\n",
    "    plt.contourf(xx,yy,y_decision, alpha=0.3, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d802b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1,gamma2, gamma3 = 0.1, 1, 10\n",
    "C1, C2, C3 = 0.001, 1,1000\n",
    "hyperparams = (gamma1, C1), (gamma1, C2),(gamma1, C3),(gamma2, C1), (gamma2, C2),(gamma2, C3),(gamma3, C1), (gamma3, C2),(gamma3, C3)\n",
    "svm_clfs = []\n",
    "\n",
    "for gamma, C in hyperparams:\n",
    "    rbf_kernel_svm_clf = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svm_clf\", SVC(kernel=\"rbf\", gamma=gamma, C=C)) \n",
    "            ])\n",
    "    rbf_kernel_svm_clf.fit(X, y)\n",
    "    svm_clfs.append(rbf_kernel_svm_clf)#这里会产生四个clf\n",
    "#将画布分成四块\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(21,15), sharex=True, sharey=True)\n",
    "\n",
    "for i, svm_clf in enumerate(svm_clfs): \n",
    "    plt.sca(axes[i // 3, i % 3])\n",
    "    plot_boundary(svm_clf, [-1.5, 2.45, -1, 1.5])\n",
    "    plot_dataset(X, y, [-1.5, 2.45, -1, 1.5])\n",
    "    gamma, C = hyperparams[i]\n",
    "    plt.title(r\"$\\gamma = {}, C={}$\".format(gamma, C), fontsize=16)\n",
    "    if i in (0, 1):\n",
    "        plt.xlabel(\"\") \n",
    "    if i in (1, 3):\n",
    "        plt.ylabel(\"\")\n",
    "plt.savefig('SVM_gamma_C.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1706f",
   "metadata": {},
   "source": [
    "## 3.3 不同数据分布条件下的不同模型\n",
    "\n",
    "改编自 sklearn https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization_classification.html#sphx-glr-auto-examples-preprocessing-plot-discretization-classification-py\n",
    "\n",
    "这个例子用到了sklearn的标准化训练流程工具：Pipeline（流水线）。我们会在后续训练流程中进行讲解\n",
    "\n",
    "这里可以先理解为，Pipeline是把各个打包好的模块排列进模型，执行时会依次执行排列好的模块。\n",
    "\n",
    "事实上，这个例子是个很好的学习流水线的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cf218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Tom Dupré la Tour\n",
    "# Adapted from plot_classifier_comparison by Gaël Varoquaux and Andreas Müller\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "\n",
    "h = 0.02  # step size in the mesh\n",
    "\n",
    "\n",
    "def get_name(estimator):\n",
    "    name = estimator.__class__.__name__\n",
    "    if name == \"Pipeline\":\n",
    "        name = [get_name(est[1]) for est in estimator.steps]\n",
    "        name = \" + \".join(name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-1, 1, 3)\n",
    "#自己试一下这个函数是在干什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b91d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of (estimator, param_grid), where param_grid is used in GridSearchCV\n",
    "# The parameter spaces in this example are limited to a narrow band to reduce\n",
    "# its runtime. In a real use case, a broader search space for the algorithms\n",
    "# should be used.\n",
    "classifiers = [\n",
    "    \n",
    "    (\n",
    "        make_pipeline(StandardScaler(), SVC(random_state=0, kernel='linear')),\n",
    "        {\"svc__C\": np.logspace(-3, 3, 20)},\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(StandardScaler(), SVC(random_state=0,kernel='poly')), #默认值 degree = 3\n",
    "        {\"svc__C\": np.logspace(-3, 3, 20)},\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "        make_pipeline(StandardScaler(), SVC(random_state=0, kernel='poly', degree = 10)), \n",
    "        {\"svc__C\": np.logspace(-3, 3, 20)},\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "        make_pipeline(StandardScaler(), SVC(random_state=0)),  #默认值 kenerl = rbf\n",
    "        {\"svc__C\": np.logspace(-3, 3, 20)},\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [get_name(e).replace(\"StandardScaler + \", \"\") for e, _ in classifiers]\n",
    "\n",
    "n_samples = 100\n",
    "datasets = [\n",
    "    make_moons(n_samples=n_samples, noise=0.2, random_state=0),\n",
    "    make_circles(n_samples=n_samples, noise=0.2, factor=0.5, random_state=1),\n",
    "    make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=2,\n",
    "        n_redundant=0,\n",
    "        n_informative=2,\n",
    "        random_state=2,\n",
    "        n_clusters_per_class=1,\n",
    "    ),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(datasets), ncols=len(classifiers) + 1, figsize=(21, 9)\n",
    ")\n",
    "\n",
    "cm_piyg = plt.cm.PiYG\n",
    "cm_bright = ListedColormap([\"#b30065\", \"#178000\"])\n",
    "\n",
    "# iterate over datasets\n",
    "for ds_cnt, (X, y) in enumerate(datasets):\n",
    "    print(f\"\\ndataset {ds_cnt}\\n---------\")\n",
    "\n",
    "    # split into training and test part\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    # create the grid for background colors\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # plot the dataset first\n",
    "    ax = axes[ds_cnt, 0]\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "    # and testing points\n",
    "    ax.scatter(\n",
    "        X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\"\n",
    "    )\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for est_idx, (name, (estimator, param_grid)) in enumerate(zip(names, classifiers)):\n",
    "        ax = axes[ds_cnt, est_idx + 1]\n",
    "\n",
    "        clf = GridSearchCV(estimator=estimator, param_grid=param_grid)\n",
    "        with ignore_warnings(category=ConvergenceWarning):\n",
    "            clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(f\"{name}: {score:.2f}\")\n",
    "\n",
    "        # plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]*[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.column_stack([xx.ravel(), yy.ravel()]))\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.column_stack([xx.ravel(), yy.ravel()]))[:, 1]\n",
    "\n",
    "        # put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm_piyg, alpha=0.8)\n",
    "\n",
    "        # plot the training points\n",
    "        ax.scatter(\n",
    "            X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\"\n",
    "        )\n",
    "        # and testing points\n",
    "        ax.scatter(\n",
    "            X_test[:, 0],\n",
    "            X_test[:, 1],\n",
    "            c=y_test,\n",
    "            cmap=cm_bright,\n",
    "            edgecolors=\"k\",\n",
    "            alpha=0.6,\n",
    "        )\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name.replace(\" + \", \"\\n\"))\n",
    "        ax.text(\n",
    "            0.95,\n",
    "            0.06,\n",
    "            (f\"{score:.2f}\").lstrip(\"0\"),\n",
    "            size=15,\n",
    "            bbox=dict(boxstyle=\"round\", alpha=0.8, facecolor=\"white\"),\n",
    "            transform=ax.transAxes,\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('SVC_data_model')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
